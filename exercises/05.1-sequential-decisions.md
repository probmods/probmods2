---
layout: exercise
title: "Sequential decisions"
description: "Markov Decision Processes and Partially-Observable Markof Decision Processes" 
---

## Exercise 1

Consider our "line-world" example from the chapter:

~~~~
var ___ = ' '; 
var D = { name: 'Donut' };

var grid = [
  ['___', '___', '___', '___',  D]
];

var mdp = makeGridWorldMDP({ grid, start: [0, 0] });

var transition = function(state, action) {
  return state + action;
};

var utility = function(state) {
  if (state === 4) {
    return 1;
  } else {
    return 0;
  }
};

var makeAgent = function() { 
  var act = function(state, timeLeft) {
    return Infer({ model() {
      var action = uniformDraw([-1, 0, 1]);
      var eu = expectedUtility(state, action, timeLeft);
      factor(100 * eu);
      return action;
    }});
  };

  var expectedUtility = function(state, action, timeLeft) {
    var u = utility(state, action);
    var newTimeLeft = timeLeft - 1;
    if (newTimeLeft === 0) {
      return u; 
    } else {
      return u + expectation(Infer({ model() {
        var nextState = transition(state, action); 
        var nextAction = sample(act(nextState, newTimeLeft));
        return expectedUtility(nextState, nextAction, newTimeLeft);
      }}));
    }
  };

  return { act };
}


var act = makeAgent().act;

var simulate = function(state, timeLeft){
  if (timeLeft === 0){
    return [];
  } else {
    var action = sample(act(state, timeLeft));
    var nextState = transition(state, action); 
    return [state].concat(simulate(nextState, timeLeft - 1))
  }
};

var startState = 0;
var totalTime = 5;
viz.gridworld(mdp.world, { trajectory : [mdp.startState] });
print("Agent's trajectory: " + simulate(startState, totalTime));
~~~~

### a) 
Change the world such that it is a loop, i.e. moving right from state `4` moves to state `0`, and moving left from state `0` moves to state `4`. How does this change the agent's sequence of actions?

### b) 
Change the agent's action space such that the agent can also move two steps at a time. How does this change the agent's sequence of actions?

### c) 
Change the agent's utility function such that the agent moves as far as possible to the right, given its available total time.

## Exercise 2

Consider this "line-world" involving a cookie shop and a donut shop:

~~~~
var ___ = ' '; 
var D = { name: 'Donut' };
var C = { name: 'Cookie' };

var grid = [
  [C, '___', '___', '___', '___', '___', D]
];

var mdp = makeGridWorldMDP({ grid, start: [3, 0] });

var transition = function(state, action) {
  return state + action;
};

var utility = function(state) {
  if (state === 6) {
    return 1;
  } else {
    return 0;
  }
};

var makeAgent = function() { 
  var act = function(state, timeLeft) {
    return Infer({ model() {
      var action = uniformDraw([-1, 0, 1]);
      var eu = expectedUtility(state, action, timeLeft);
      factor(100 * eu);
      return action;
    }});
  };

  var expectedUtility = function(state, action, timeLeft) {
    var u = utility(state, action);
    var newTimeLeft = timeLeft - 1;
    if (newTimeLeft === 0) {
      return u; 
    } else {
      return u + expectation(Infer({ model() {
        var nextState = transition(state, action); 
        var nextAction = sample(act(nextState, newTimeLeft));
        return expectedUtility(nextState, nextAction, newTimeLeft);
      }}));
    }
  };

  return { act };
}

var act = makeAgent().act;

var simulate = function(state, timeLeft){
  if (timeLeft === 0){
    return [];
  } else {
    var action = sample(act(state, timeLeft));
    var nextState = transition(state, action); 
    return [state].concat(simulate(nextState, timeLeft - 1))
  }
};

var startState = 3;
var totalTime = 5;
~~~~

Bob starts out in between the donut shop and the cookie shop. Assume you observe Bob go to the donut shop in 3 time steps. Edit the code above to write a model to *infer* Bob's utility function for cookies and donuts. Use any reasonable prior. 


## Exercise 3

Use the codebox below to explore different levels of softmax noise. Find a setting of `utilityTable` and `alpha` such that the agent goes to West and East equally often and nearly always takes the most direct route to both East and West. Included below is code for simulating many trajectories and returning the trajectory length. You may find it helpful to extend this code to measure whether the route taken by the agent is direct or not. 

~~~~
///fold: makeHikeMDP, set up world
var makeHikeMDP = function(options) {
  var H = { name: 'Hill' };
  var W = { name: 'West' };
  var E = { name: 'East' };
  var ___ = ' ';
  var grid = [
    [___, ___, ___, ___, ___],
    [___, '#', ___, ___, ___],
    [___, '#',  W , '#',  E ],
    [___, ___, ___, ___, ___],
    [ H ,  H ,  H ,  H ,  H ]
  ];
  return makeGridWorldMDP(_.assign({ grid }, options));
};

var mdp = makeHikeMDP({
  start: [0, 1],
  totalTime: 13,
  transitionNoiseProbability: 0.1
});

var world = mdp.world;
var startState = mdp.startState;
var makeUtilityFunction = mdp.makeUtilityFunction;
///

var utilityTable = {
  East: 10,
  West: 1,
  Hill: -10,
  timeCost: -.1
}

// Create parameterized agent
var utility = makeUtilityFunction(utilityTable);
var alpha = 1;  // <- SOFTMAX NOISE
var agent = makeMDPAgent({ utility, alpha }, world);

// Generate a single trajectory, draw
var trajectory = simulateMDP(startState, world, agent, 'states');
viz.gridworld(world, { trajectory });

// Generate 100 trajectories, plot distribution on lengths
var trajectoryDist = Infer({
  model() {
    var trajectory = simulateMDP(startState, world, agent);
    return { trajectoryLength: trajectory.length }
  },
  method: 'forward',
  samples: 100
});
viz(trajectoryDist);
~~~~

