---
layout: exercise
title: "Rational process models - readings"
description: "The psychological reality of inference algorithms." 
---

## 1. [Partial mental simulation explains fallacies in physical reasoning](https://par.nsf.gov/servlets/purl/10350504) by Ilona Bass, Kevin A. Smith, Elizabeth Bonawitz, \& Tomer D. Ullman

##### a) What is the "physical conjunction fallacy"? In what way is it a fallacy?

[chatGPT misreads "physical conjunction fallacy" as just "conjunction fallacy" and gives a basic explanation of what a conjunction fallacy is. It's not an interesting answer, so it's not included here.]

##### b) The authors argue that humans have limited cognitive resources and so much rely on carefully-optimized partial simulation when answering physics questions. How does this help explain the physical conjunction fallacy?

Here, chatGPT actualy starts off well and then goes off the rails:

> Partial simulation involves mentally representing only a subset of the features or variables relevant to a physical event, rather than a complete and accurate representation of all the variables involved. This allows humans to quickly and efficiently reason about complex physical situations, but it can also lead to errors in judgment when the partial simulation omits important variables or interactions.
>
>In the case of the physical conjunction fallacy, people may rely on partial simulations that emphasize the similarity between two events or the salience of their conjunction, rather than their individual probabilities. For example, a person may mentally simulate the characteristics of a vegetarian marathon runner and find it a more plausible scenario than a vegetarian who is not a marathon runner, because the conjunction of the two events seems more coherent or vivid in their minds.
>
>Thus, the physical conjunction fallacy can be seen as a result of the limitations of human cognitive resources and the heuristics that people use to reason about complex physical situations. By understanding these limitations and biases, we can work to improve our reasoning skills and avoid common errors in judgment.

(If you are wondering what happened here, try asking chatGPT about the conjunction fallacy.)

## 2. [One and Done? Optimal Decisions From Very Few Samples](https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.12101). Vul, Goodman, Griffiths, Tenenbaum (2014). Cognitive Science.

##### a) A basic fact about sampling methods is that the more samples one takes, the more accurate the answer. Why would it ever be *rational* to not take large numbers of samples? 

chatGPT is again sometimes spot-on, and sometimes deeply confused:

> In Bayesian models of cognition, it is true that taking more samples generally leads to more accurate answers. However, it is not always rational or feasible to take large numbers of samples. There are several reasons why taking a large number of samples may not be rational or necessary:
> 
> Time and resource constraints: In some situations, it may simply not be feasible to take a large number of samples due to time or resource constraints. For example, if you are making a decision in a high-pressure, time-sensitive situation, you may not have the luxury of taking a large number of samples.
> 
> Diminishing returns: Taking additional samples beyond a certain point may not result in a significant improvement in accuracy, as the additional samples may not contain much new information. In other words, there may be diminishing returns to taking more samples.
> 
> Prior knowledge: In some cases, prior knowledge about the situation can be used to inform the sampling process, allowing for a more efficient use of resources. For example, if you are making a decision about whether to invest in a particular stock, you may be able to use your prior knowledge of the stock market to narrow down the range of possible outcomes, and thus require fewer samples to arrive at a decision.
> 
> Risk tolerance: Taking more samples may involve more risk, as it may expose you to more uncertainty and variability in the data. In some cases, it may be more rational to make a decision based on a smaller number of samples in order to reduce the risk of being exposed to extreme or outlier data points.
> 
> Overall, while taking more samples can improve the accuracy of Bayesian models of cognition, it is not always rational or necessary to take large numbers of samples. The decision of how many samples to take should be based on a careful consideration of the specific situation, including time and resource constraints, the potential for diminishing returns, prior knowledge, and risk tolerance.

<!--
Rational Use of Cognitive Resources: Levels of Analysis Between the Computational and the Algorithmic, Griffiths, Lieder, Goodman (2015). 

**One and Done** :One concern about Bayesian models is that inference takes too long. But what if you actually didn't need to run MCMC that long? @vul2014one

One and Done? Optimal Decisions From Very Few Samples, Vul, Goodman, Griffiths, Tenenbaum (2014). Cognitive Science.

Remembrance of inferences past: Amortization in human hypothesis generation. Dasgupta, Schulz, Goodman & Gershman. (2018). Cognition.

The anchoring bias reflects rational use of cognitive resources. Lieder, F., Griffiths, T. L., Huys, Q. J. M., & Goodman, N. D. (2018). Psychonomic Bulletin & Review.

Empirical evidence for resource-rational anchoring and adjustment. Lieder, F., Griffiths, T. L., Huys, Q. J. M., & Goodman, N. D. (2018). Psychonomic Bulletin & Review.

**Perceptual instability as MCMC** Could sampling explain perceptual instability? @gershman2009perceptual

Perceptual Multistability as Markov Chain Monte Carlo Inference. Gershman, Vul, Tenenbaum (2009).

Theory Acquisition as Stochastic Search. Ullman, Goodman, and Tenenbaum (2010).

Exemplar models as a mechanism for performing Bayesian inference. Shi, Griffiths, Feldman, Sanborn (2010).
-->

## Extras
#### Extra Psychology
* Wikipedia has a brief discussion of the [conjunction fallacy](https://en.wikipedia.org/wiki/Conjunction_fallacy)
* Wikipedia also has a [reasonably complete list of commonly-discussed biases](https://en.wikipedia.org/wiki/List_of_cognitive_biases), with links to more complete discussions. 
* The two papers above are part of a long-running debate in the literature about just how rational human cognition is. To get a sense of the other side in this debate, read "[How robust are probabilistic models of higher-level cognition](https://journals.sagepub.com/doi/pdf/10.1177/0956797613495418?casa_token=az-oW__aiZcAAAAA:efPp3X1NEL8Us-vsyVorN2FD3Nmh1fFby3VeTwN1CygfpYxVgkCtbK3pdHQWV5eqwh0IS5Fre9S4), Ernie Davis and Gary Marcus.